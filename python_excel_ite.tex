%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Author style for INFORMS Transactions on Education (ited)
%% Mirko Janc, Ph.D., INFORMS, pubtech@informs.org
%% ver. 0.92, June 2009 -- default options: single-spaced, double-blinded
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\documentclass[ited]{informs3}                      % for a regular run
%\documentclass[ited,nonblindrev]{informs3}          % for review, not blinded
%\documentclass[ited,blindrev,copyedit]{informs3}    % spaced for copyediting
\documentclass[ited,blindrev]{informs3}              % for review, blinded

\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}

% If hyperref is used, dvi-to-ps driver of choice must be declared as
%   an additional option to the \documentstyle. For example
%\documentclass[dvips,ited]{informs1}      % if dvips is used 
%\documentclass[dvipsone,ited]{informs1}   % if dvipsone is used, etc. 

% Private macros here (check that there is no clash with the style)
\newcommand{\code}[1]{\texttt{#1}}

\definecolor{LightGray}{gray}{0.9}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{mystyle}{
	backgroundcolor=\color{LightGray},   
    commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegreen},
	stringstyle=\color{codepurple},
	basicstyle=\footnotesize\ttfamily,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
}

\lstset{style=mystyle}

% Natbib setup for author-year style
\usepackage{natbib}
 \bibpunct[, ]{(}{)}{,}{a}{}{,}%
 \def\bibfont{\small}%
 \def\bibsep{\smallskipamount}%
 \def\bibhang{24pt}%
 \def\newblock{\ }%
 \def\BIBand{and}%

%% Setup of theorem styles. Outcomment only one. 
%% Preferred default is the first option.
\TheoremsNumberedThrough     % Preferred (Theorem 1, Lemma 1, Theorem 2)
%\TheoremsNumberedByChapter  % (Theorem 1.1, Lema 1.1, Theorem 1.2)

%% Setup of the equation numbering system. Outcomment only one.
%% Preferred default is the first option.
\EquationsNumberedThrough    % Default: (1), (2), ...
%\EquationsNumberedBySection % (1.1), (1.2), ...

% In the reviewing and copyediting stage enter the manuscript number.
%\MANUSCRIPTNO{} % When the article is logged in and DOI assigned to it,
                 %   this manuscript number is no longer necessary

%%%%%%%%%%%%%%%%
\begin{document}
%%%%%%%%%%%%%%%%

% Outcomment only when entries are known. Otherwise leave as is and 
%   default values will be used.
%\setcounter{page}{1}
%\VOLUME{00}%
%\NO{0}%
%\MONTH{Xxxxx}% (month or a similar seasonal id)
%\YEAR{0000}% e.g., 2005
%\FIRSTPAGE{000}%
%\LASTPAGE{000}%
%\SHORTYEAR{00}% shortened year (two-digit)
%\ISSUE{0000} %
%\LONGFIRSTPAGE{0001} %
%\DOI{10.1287/xxxx.0000.0000}%

% Author's names for the running heads
% Sample depending on the number of authors;
% \RUNAUTHOR{Jones}
% \RUNAUTHOR{Jones and Wilson}
% \RUNAUTHOR{Jones, Miller, and Wilson}
% \RUNAUTHOR{Jones et al.} % for four or more authors
% Enter authors following the given pattern:
\RUNAUTHOR{Isken}

% Title or shortened title suitable for running heads. Sample:
% \RUNTITLE{Bundling Information Goods of Decreasing Value}
% Enter the (shortened) title:
\RUNTITLE{Python for spreadsheet type modeling}

% Full title. Sample:
% \TITLE{Bundling Information Goods of Decreasing Value}
% Enter the full title:
\TITLE{Using Python for spreadsheet type modeling}

% Block of authors and their affiliations starts here:
% NOTE: Authors with same affiliation, if the order of authors allows, 
%   should be entered in ONE field, separated by a comma. 
%   \EMAIL field can be repeated if more than one author
\ARTICLEAUTHORS{%
\AUTHOR{Mark W. Isken}
\AFF{Oakland University, \EMAIL{isken@oakland.edu}, \URL{http://www.sba.oakland.edu/faculty/isken/}}
% Enter all authors
} % end of the block

\ABSTRACT{%
TODO: Text of your abstract % Enter your abstract
}%

% Sample
%\KEYWORDS{deterministic inventory theory; infinite linear programming duality; 
%  existence of optimal policies; semi-Markov decision process; cyclic schedule}

% Fill in data. If unknown, outcomment the field
\KEYWORDS{python, spreadsheet modeling}
\HISTORY{}

\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Samples of sectioning (and labeling) in ITED
% NOTE: (1) \section and \subsection do NOT end with a period
%       (2) \subsubsection and lower need end punctuation
%       (3) capitalization is as shown (title style).
%
%\section{Introduction.}\label{intro} %%1.
%\subsection{Duality and the Classical EOQ Problem.}\label{class-EOQ} %% 1.1.
%\subsection{Outline.}\label{outline1} %% 1.2.
%\subsubsection{Cyclic Schedules for the General Deterministic SMDP.}
%  \label{cyclic-schedules} %% 1.2.1
%\section{Problem Description.}\label{problemdescription} %% 2.

% Text of your paper here

\section{Introduction}

% The opening part of the what-if notebook has some language for the motivation behind this module.

Why I created 

- more topics I wanted to cover than were possible in PCDA course
- weave in more SE type material which is often overlooked in BA programs

Excel is widely used for building and using models of business problems to explore the impact of various model inputs on key outputs. Built in "what if?" tools such as Excel [Data Tables](https://support.microsoft.com/en-us/office/calculate-multiple-results-by-using-a-data-table-e95e2487-6ca6-4413-ad12-77542a5ea50b) and [Goal Seek](https://support.microsoft.com/en-us/office/use-goal-seek-to-find-the-result-you-want-by-adjusting-an-input-value-320cb99e-f4a4-417f-b1c3-4f369d6e66c7) are well known to power spreadsheet modelers. How might we do similar modeling and analysis using Python?

Limitations of spreadsheets such as reproducibility and automation.


While Python has been gaining momentum in the business analytics world, it is often used for data wrangling, analysis and visualization of tablular data using tools like pandas and matplotlib or Seaborn. You can find some great examples at [Chris Moffit's Practical Business Python blog](https://pbpython.com/). I use Python all the time for such tasks and teach a course called [Practical Computing for Data Analytics](http://www.sba.oakland.edu/faculty/isken/courses/mis5470/) that is Python (and R) based. But, it got me to thinking. What about those things for which Excel is well suited such as building formula based models and doing sensitivity analysis on these models? What would those look like in Python?

Quant Econ example

PBB blog


Teach relevant Python to business students using familiar and relevant modeling examples.
Give sense of software development process and design decisions
Model a learning journey
Teach students to think and act like a software developer, not just an analyst

\section{Module positioning and structure}

PCDA ends with intro to sklearn and AAP begins with review of sklearn and some more ML content - logistic regression with regularization

What kind of Python background do students need to have in order to be ready for this EwP module? This module does presume a basic familiarity with Python fundamentals for data analysis such as:

\begin{itemize}
	\item variables, artithmetic and boolean operators, and basic data types,
	\item data structures such as lists, dictionaries, tuples, NumPy arrays and pandas dataframes,
	\item flow control such as branching with \texttt{if \ldots else} and looping with \texttt{for} and \texttt{while}
	\item module imports,
	\item using built in functions and accessing methods and properties of objects,
	\item creating functions,
	\item basic use of NumPy and pandas for data wrangling and analysis,
	\item basic plotting with matplotlib.
\end{itemize}

The EwP module could easily be used as part of a semester long Python based analytics course. At our institution, this module is part of a business course entitled "Advanced Analytics with Python" (\href{http://www.sba.oakland.edu/faculty/isken/courses/mis6900}{AAP}). The students taking this course have already taken my "Practical Computing for Business Analytics" (\href{http://www.sba.oakland.edu/faculty/isken/courses/mis5470}{PCDA}) course in which they spend about half the semester learning R and the other half learning Python, both in the context of business analytics. Some Linux basics are also part of the PCDA course. The students have also already taken "Business Analytics" (\href{http://www.sba.oakland.edu/faculty/isken/courses/mis5460}{BA}) which is a spreadsheet based introduction to business analytics. The BA and PCDA courses have historically been offered in face to face mode in a computer teaching lab. Since 2020, these two courses have been also offered as online, asynchronous courses. The newer AAP course has been offered since 2021 in an online asynchronous mode. All three courses have extensive course websites that are publicly accessible, including access to all of the video content and files needed. We will describe the AAP course web in more detail below in the context of the EwP module.

The EwP module is made of three submodules. The first of these focuses on building and using a typical spreadsheet model using Python. Then the functionality developed for doing this type of modeling in Python is deployed as a reusable package. We end with an introduction to using Python to manipulate Excel files, an extremely common use case.

Combination of Jupyter notebooks, Python scripts, videos walking through the notebooks and scripts, all accessible from submodule specific course web pages. Some background on Jupyter notebooks for analytics. Questions and coding challenges sprinkled throughout the notebooks - answers at bottom.

\section{Submodule 1: The modeling notebooks}

There are two overarching learning objectives for this first set of Jupyter notebooks. Students learn how Python might be used to do something they are quite familiar with doing in a spreadsheet - model building and sensitivity analysis. At the same time, students encounter, as they are needed, more advanced Python programming techniques such as object oriented programming, ADD MORE FROM THE MODULES. In this way, the computational problem to be solved drives the introduction of more advanced Python concepts and techniques instead of such things being presented in a vacuum. I make it a point to try to convey the notion that there are often multiple possible approaches by embarking on one path and then starting over and doing things in a different way. MORE NEEDED
 
 
\subsection{Notebook 1: Modeling and data tables}

\begin{quote}
	For example, here's a high level screenshot of a model that I assign for homework in my [MIS 4460/5460 Business Analytics class](http://www.sba.oakland.edu/faculty/isken/courses/mis5460/) (a spreadsheet based modeling class).
	It's a really simple model in which we are selling a single product that we produce. There is a fixed cost to producing the product as well as a variable production cost per unit. We can sell the product for some price and we believe that demand for the product is related to the selling price through a power function. Let's assume for now that we have sufficient capacity to produce to demand and that all inputs are deterministic (we'll deal with simulating uncertainty later in this document).
	
	The details aren't so important right now as is the overall structure of the model. There's a few key inputs and some pretty straightforward formulas for computing cost, revenue and profit. Notice the 1-way Data Table being used to explore how profit varies for different selling prices. There's a graph driven by the Data Table and some Text Boxes used for annotation and summary interpretative comments. There's a button that launches Goal Seek to find the break even selling price and a 2-way Data Table (not shown) to explore the joint effect of selling price and variable cost. Classic Excel modeling stuff. How might we go about building a similar model using Python?  
	
	What if we wanted to push it a little further and model some of the key inputs with probability distributions to reflect our uncertainty about their values? In the Excel world, we might use add-ins such as @Risk which allow uncertain quantities to be directly modeled with probability distributions. For example, we might have a key input such as the exponent in the power function that relates selling price to demand that is highly uncertain. By modeling it with a probability distribution and then sampling from that distribution many times (essentially by recalcing the spreadsheet) we can generate a bunch of possible values for key outputs (e.g. profit) and use statistics to summarize these outputs using things like histograms and summary stats. Often this type of simulation model is referred to as a *Monte-Carlo* model to suggest repeated sampling from one or more probability distributions within an otherwise pretty static model. If you want to see such models in action, check out my [Simulation Modeling with Excel page](http://www.sba.oakland.edu/faculty/isken/courses/mis5460/simulation.html) from my Business Analytics course. Again, how might we do this with Python?
\end{quote}


The first focuses on building a simple what-if model and doing sensitivity analysis much like one would do using Excel's Data-Table functionality.

This example is based on one in the [spreadsheet modeling textbooks I've used in my classes since 2001](https://host.kelley.iu.edu/albrightbooks/). In both books, they introduce the "Walton Bookstore" problem in the chapter on Monte-Carlo simulation. Here is the basic problem (with a few modifications):

\begin{itemize}
	\item we have to place an order for a perishable product (e.g. a calendar),
	\item there is a known unit cost for each one ordered,
	\item we have a known selling price,
	\item demand is uncertain but we can model it with some simple probability distribution,
	\item for each unsold item, we can get a partial refund of our unit cost,
	\item we need to select the order quantity for our one order for the year; orders can only be in multiples of 25.
\end{itemize}

\subsubsection{Build first model - procedural approach}
 
The notebook begins with a suggestion to start with a very simple model that ignores the uncertainty in demand and that is not object oriented. Proceeding much like we would in Excel, we store base input values in variables. 

\begin{lstlisting}[language=Python]
# Base inputs
unit_cost = 7.50
selling_price = 10.00
unit_refund = 2.50

# Demand parameters
demand_mean = 193
demand_sd = 40

# Deterministic model
demand = demand_mean

# Initial value for order quantity - this is the decision variable
order_quantity = 200
\end{lstlisting}

Then students are given some skeleton code and must finish the expressions for computing key intermediate outputs (\code{order_cost, sales_revenue, refund_revenue} and the final output, \code{profit}. Answers are provided at the bottom of the notebook so that students can attempt to finish the code but have a resource to correctly complete the code and move on. The screencast associated with the notebook also shows me completing the code. Using skeleton code in this way has worked well both for face to face lab based versions of this type of course as well as for online asynchronous versions.

\begin{lstlisting}[language=Python]
order_cost = unit_cost * order_quantity
sales_revenue = ??? * selling_price
refund_revenue = ??? * unit_refund
profit = sales_revenue + refund_revenue - order_cost
\end{lstlisting}

At this point we discuss a fundamental difference between the computing model of Excel and that of Jupyter notebooks. While spreadsheets respond automatically to changes, Jupyter notebooks require rerunning all code cells that include or follow the changed code.

\subsubsection{Sensitivity analysis}

Since order quantity is the key decision variable, we might want to see how profit changes for different order quantities in this first simplified model. In Excel, the Data Table tool provides an easy way to do this and is a staple of spreadsheet based management science textbooks. In a Data Table, a range of order quantities can be used as row or column input and one or more output values can be computed. In Python, we can rely on the built in vectorized behavior of the language. A range of order quantities is created as a NumPy array and then can be used directly to compute vectors of all of the intermediate and final output variables. Much like Data Tables, vectorized computations avoid having to explicitly iterate (loop) through a collection of input values.

A natural next step is to do the equivalent of an Excel 2-way Data Table. Can't do 2 vectors since we need all combinations of entries in each vector. List comprehensions provide a compact way to create nested loops over the two vectors. By creating a profit function that takes all of the base inputs as arguments, we can construct a list comprehension that does what an Excel 2-Way Data Table does. Even better, this actually allows us to do the equivalent of an n-Way Data Table.

\begin{lstlisting}[language=Python]
	def bookstore_profit(unit_cost, selling_price, unit_refund, order_quantity, demand):
	'''
	Compute profit in bookstore model
	'''
		order_cost = unit_cost * order_quantity
		sales_revenue = np.minimum(order_quantity, demand) * selling_price
		refund_revenue = np.maximum(0, order_quantity - demand)
		profit = sales_revenue + refund_revenue - order_cost
		return profit
	
	# Set up input vector ranges	
	demand_range = np.arange(50, 301, 5)
	order_quantity_range = np.arange(50, 301, 25)
	
	# Create data table (as a list of tuples)
	data_table_1 = [(d, oq, bookstore_profit(unit_cost, selling_price, unit_refund, oq, d)) 
	for d in demand_range for oq in order_quantity_range]
	
	# Convert to dataframe
	dtbl_1_df = pd.DataFrame(data_table_1, columns=['Demand', 'OrderQuantity', 'Profit'])
	
\end{lstlisting}

TODO - add output listing and plot

\subsubsection{The object nature of Python}

Introducing basic OO concepts is a primary learning objective. It's not clear whether an OO or a non-OO approach will end up making the most sense for doing spreadsheet type modeling. This uncertainty is made explicit in the notebook and students are led on a bit of a journey of discovery as we explore different software designs for our modeling problem. I purposefully designed the notebooks in this way to show students that the path to a solution is not necessarily linear and that giving yourself the freedom to explore alternatives, many of which will be dead ends, can lead to a rich learning experience. It is also more realistic in the sense that this is how most real problems are solved. It's analogous to the idea that mathematical proofs usually don't reflect the myriad of failed approaches that were tried but that ultimately contributed to the final product.

In preparation for building an object oriented version of the model, basic object concepts are reviewed. Since most students have done some Excel VBA programming in a previous course, I refer back to a few properties and methods of the Excel \code{Worksheet} object. In Python, everything is an object. Using Python lists as an example, we explore some of its attributes such as methods for appending items to a list and reversing the order of its elements. The \code{dir} function is used to see all of an object's attributes and we see that even things like integers are objects in Python. With this basic object refresher, we are ready to do some actual object oriented programming and create our own objects - well, actually classes.

For our initial design of a \code{BookstoreModel} class we make all of the base inputs attributes (properties) and then add method attributes to compute outputs such as costs, revenues and profits. Student can easily see the mapping between things in the initial procedural model and this new object oriented version of the model. I highlight several important concepts and syntactical details of doing OO programming Python. Again, the goal is to weave in these more advanced Python programming concepts within the context of a very familiar modeling problem. This section of the notebook ends with us using our \code{BookstoreModel} class to an actual model objects with all of its base inputs instantiated with values. Before moving on students are presented with a few challenges involving enhancements to the \code{BookstoreModel} class.








\subsection{Notebook 2: Goal seek}

The next submodule explores the creation and use of goal seeking capability so that we can do things like finding the break-even point in our model.
 
\subsection{Notebook 3: Monte-Carlo simulation}

\section{Submodule 2: The packaging notebooks}
\subsection{Notebook 4: Project packaging}
\subsection{Notebook 5: Documentation}

\section{Submodule 3: The wrangling notebook}
\subsection{Notebook 6: Manipulating Excel files with Python}

\section{Classroom experience}

\section{Random notes}
Learning good Python programming practices via learning to model in similar way that students learn good spreadsheet practices through building spreadsheet models using the W\&A textbook.

How aap course fits in relation to pcda course. Could also be second part of a fully Python based course. Builds on basic intro Python concepts and skills.

The Quant Econ website is a good example of another use of Python for typical Excel things.

% Acknowledgments here
\ACKNOWLEDGMENT{%
% Enter the text of acknowledgments here
}% Leave this (end of acknowledgment)


% Appendix here
% Options are (1) APPENDIX (with or without general title) or 
%             (2) APPENDICES (if it has more than one unrelated sections)
% Outcomment the appropriate case if necessary
%
% \begin{APPENDIX}{<Title of the Appendix>}
% \end{APPENDIX}
%
%   or 
%
% \begin{APPENDICES}
% \section{<Title of Section A>}
% \section{<Title of Section B>}
% etc
% \end{APPENDICES}


% References here (outcomment the appropriate case) 

% CASE 1: BiBTeX used to constantly update the references 
%   (while the paper is being written).
%\bibliographystyle{informs2014} % outcomment this and next line in Case 1
%\bibliography{<your bib file(s)>} % if more than one, comma separated

% CASE 2: BiBTeX used to generate mypaper.bbl (to be further fine tuned)
%\input{mypaper.bbl} % outcomment this line in Case 2

\end{document}


